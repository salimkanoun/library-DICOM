{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit9a8409779cd04c3cbd0c5f1e859a644e",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "from library_dicom.dicom_processor.tools.series import get_series_object\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/home/deeplearning/AHL/AHL_JSON'\n",
    "list_dir_json = os.listdir(json_path)\n",
    "list_json = []\n",
    "\n",
    "remo = [list_dir_json[254]]\n",
    "remo.append(list_dir_json[371])\n",
    "remo.append(list_dir_json[471])\n",
    "for r in remo : \n",
    "    list_dir_json.remove(r)\n",
    "\n",
    "for file_ in list_dir_json : \n",
    "    list_json.append([os.path.join(json_path, file_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv \n",
    "csv_path= '/home/deeplearning/AHL/AHL2011_NIFTI.csv'\n",
    "dataset = []\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    dataset = []\n",
    "    for row in reader :\n",
    "        dataset.append(row)\n",
    "        \n",
    "del dataset[0] #enlever premi√®re ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3976\n"
     ]
    }
   ],
   "source": [
    "json_path_1 = '/home/deeplearning/AHL/AHL_JSON/AHL_JSON_1'\n",
    "list_dir_json_1 = os.listdir(json_path_1)\n",
    "list_json_1 = []\n",
    "for file_ in list_dir_json_1 : \n",
    "    list_json_1.append([os.path.join(json_path_1, file_)])\n",
    "\n",
    "print(len(list_json_1))\n",
    "\n",
    "new_liste = []\n",
    "for data in dataset : \n",
    "    study_uid = data[2]\n",
    "    for json_ in list_json_1 :\n",
    "        #print(json_) \n",
    "        with open(json_[0]) as json_file : \n",
    "            reader = json.load(json_file)\n",
    "\n",
    "            uid_json = reader[\"study\"][\"StudyInstanceUID\"]\n",
    "\n",
    "            if study_uid == uid_json : \n",
    "                new_liste.append(json_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_json = list_json + new_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/deeplearning/AHL/AHL_JSON/AHL_JSON_1'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-51a307c2f591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliste\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'study'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StudyInstanceUID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/deeplearning/AHL/AHL_JSON/AHL_JSON_1'"
     ]
    }
   ],
   "source": [
    "\n",
    "index = []\n",
    "\n",
    "for liste in list_json : \n",
    "    print(list_json.index(liste))\n",
    "    patient_id = []\n",
    "    study_uid = []\n",
    "    study = []\n",
    "    path = []\n",
    "    manufacturer = []\n",
    "    unit = []\n",
    "    modal = []\n",
    "\n",
    "    with open(liste[0]) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "        for info in reader['study']['StudyInstanceUID'] : \n",
    "                study_uid.append(info)\n",
    "                study_uid_json = \"\".join(study_uid)\n",
    "\n",
    "        for info in reader['patient']['PatientID'] : \n",
    "                patient_id.append(info)\n",
    "                patient_id_json = \"\".join(patient_id)\n",
    "\n",
    "        for info in reader['study']['StudyDescription'] : \n",
    "                study.append(info)\n",
    "                study_json = \"\".join(study)\n",
    "\n",
    "        for info in reader['path'] : \n",
    "                path.append(info)\n",
    "                path_json = \"\".join(path)\n",
    "\n",
    "        for info in reader[\"series\"]['Manufacturer'] : \n",
    "                manufacturer.append(info)\n",
    "                manufacturer_json = \"\".join(manufacturer)\n",
    "\n",
    "\n",
    "        for info in reader[\"series\"][\"Modality\"] : \n",
    "                modal.append(info)\n",
    "                modal_json = \"\".join(modal)\n",
    "\n",
    "        liste.append(path_json)\n",
    "        liste.append(patient_id_json)\n",
    "        liste.append(study_uid_json)\n",
    "        liste.append(study_json)\n",
    "        liste.append(manufacturer_json)\n",
    "        liste.append(modal_json)\n",
    "\n",
    "        if modal_json != 'CT' : \n",
    "\n",
    "                #Units\n",
    "                try : \n",
    "                        for info in reader[\"series\"][\"Units\"] : \n",
    "                                unit.append(info)\n",
    "                                unit_json = \"\".join(unit)\n",
    "\n",
    "                        liste.append(unit_json)\n",
    "                        #philips tags\n",
    "                        if 'philips' in  manufacturer_json.lower(): \n",
    "                                liste.append([reader[\"philips_tags\"]['PhilipsSUVFactor'],reader[\"philips_tags\"][\"PhilipsBqMlFactor\"] ])\n",
    "\n",
    "                        #Radiopharmaceutical Date time\n",
    "                        liste.append(reader[\"radiopharmaceutical\"][\"RadiopharmaceuticalStartDateTime\"])\n",
    "\n",
    "                        #decay correction\n",
    "                        liste.append(reader[\"series\"][\"DecayCorrection\"])\n",
    "\n",
    "                        #series acquisition date \n",
    "                        liste.append(reader[\"series\"][\"AcquisitionDate\"])\n",
    "                        #series acquisition time \n",
    "                        liste.append(reader[\"series\"][\"AcquisitionTime\"])\n",
    "\n",
    "                        #series date\n",
    "                        liste.append(reader[\"series\"][\"SeriesDate\"])\n",
    "                        #serie time \n",
    "                        liste.append(reader[\"series\"]['SeriesTime'])\n",
    "                except Exception as err : \n",
    "                        print(err)\n",
    "                        index.append(list_json.index(liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list PT only \n",
    "PT_series = []\n",
    "for serie in list_json : \n",
    "    if 'PT' in serie : \n",
    "        PT_series.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/deeplearning/AHL/AHL_JSON/1.2.840.113619.2.290.3.279748722.295.1383548122.747.json',\n",
       " '/home/deeplearning/AHL/AHL_Validated_DICOM/13011101051024/pet0/1.2.840.113619.2.290.3.279748722.295.1383548122.747',\n",
       " '13011101051024',\n",
       " '1.2.840.113619.2.290.3.279748722.295.1383548122.441',\n",
       " 'PET0',\n",
       " 'GE MEDICAL SYSTEMS',\n",
       " 'PT',\n",
       " 'BQML',\n",
       " '20131104084500.00',\n",
       " 'START',\n",
       " '20131104',\n",
       " '101032',\n",
       " '20131104',\n",
       " '095621']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#SEARCH WHAT WE NEED : MANUFACTURER, UNITS, RADIOPHARMECEUTICAL DATETIME ... \n",
    "PT_series[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['GE MEDICAL SYSTEMS', 'Philips Medical Systems', 'Philips', 'SIEMENS', 'CPS']\n"
     ]
    }
   ],
   "source": [
    "manu = []\n",
    "for serie in PT_series : \n",
    "    if serie[5] not in manu : \n",
    "        manu.append(serie[5])\n",
    "\n",
    "print(manu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "def parse_datetime(date_time):\n",
    "        #remove microsecond at it is inconstant over dicom\n",
    "        if '.' in date_time : \n",
    "            date_time = date_time[0 : date_time.index('.')]\n",
    "        #parse datetime to date objet\n",
    "        return datetime.strptime(date_time, \"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "list_json = os.listdir('/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON')\n",
    "\n",
    "json_data = []\n",
    "for json_ in list_json : \n",
    "    json_data.append(os.path.join('/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON', json_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON/1.3.12.2.1107.5.1.4.11029.30000013112609200631200004819.json\n-1.0\nSIEMENS\nPET_Screening\n/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON/1.3.12.2.1107.5.1.4.11029.30000014071608553059300017695.json\n-1.0\nSIEMENS\nPET_Screening\n/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON/1.3.12.2.1107.5.1.4.11062.30000014021208495965600007463.json\n-1.0\nSIEMENS\nPET_Screening\n/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON/1.3.12.2.1107.5.1.4.1007.30000013010209284662500026012.json\n-1.0\nSIEMENS\nPET_Screening\n/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON/1.3.12.2.1107.5.1.4.11061.30000013061008312785900010231.json\n-1.0\nSIEMENS\nPET_24weeks\n/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON/1.3.12.2.1107.5.1.4.1007.30000013070807334640600005039.json\n-1.0\nSIEMENS\nPET_Screening\n/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/RELEVANCE_JSON/1.3.12.2.1107.5.1.4.11061.30000013011608121317100003951.json\n-1.0\nSIEMENS\nPET_Screening\n"
     ]
    }
   ],
   "source": [
    "for liste in json_data : \n",
    "     with open(liste) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "\n",
    "        manu = reader['series']['Manufacturer']\n",
    "        #print(manu)\n",
    "        type_ = reader['study'][\"AccessionNumber\"]\n",
    "        series_date = reader['series'][\"SeriesDate\"]\n",
    "        series_time = reader['series'][\"SeriesTime\"]\n",
    "        #print(series_time)\n",
    "        acqui_date = reader['series'][\"AcquisitionDate\"]\n",
    "        acqui_time = reader['series'][\"AcquisitionTime\"]\n",
    "        if series_date != 'Undefined' and series_time != 'Undefined' and acqui_date != 'Undefined' and acqui_time != 'Undefined' : \n",
    "            series_datetime = series_date + series_time\n",
    "            acqui_datetime = acqui_date + acqui_time\n",
    "\n",
    "\n",
    "            parse_serie = parse_datetime(series_datetime)\n",
    "            parse_acquistion = parse_datetime(acqui_datetime)\n",
    "            \n",
    "\n",
    "            if (parse_acquistion - parse_serie).total_seconds() < 0 and manu == 'SIEMENS' and reader['series']['Modality']== 'PT': \n",
    "                print(liste)\n",
    "                print((parse_acquistion - parse_serie).total_seconds())\n",
    "                print(manu)\n",
    "                print(type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['/home/deeplearning/AHL/AHL_JSON/1.3.12.2.1107.5.6.1.10011.30000014060211491892100000000.json', '/home/deeplearning/AHL/AHL_Validated_DICOM/53011101871015/PET4/imagys_AHL2011_53011101871015_1ccc941e-13d8-469a-a618-2d5f7400fbce', '53011101871015', '1.2.250.1.38.2.1.102.140425142507.103224041', 'PET4', 'CPS', 'PT', 'BQML', 'Undefined', 'START', '20140602', '130348.234000', '20140602', '134918.000000']\n['/home/deeplearning/AHL/AHL_JSON/1.3.12.2.1107.5.6.1.10011.30000014062310110704600000000.json', '/home/deeplearning/AHL/AHL_Validated_DICOM/53011101871016/PET4/imagys_AHL2011_53011101871016_accc72fe-77d6-4a93-be94-c8a70abc480f', '53011101871016', '1.2.250.1.38.2.1.102.140507141946.103250728', 'PET4', 'CPS', 'PT', 'BQML', 'Undefined', 'START', '20140623', '111058.203000', '20140623', '121107.000000']\n['/home/deeplearning/AHL/AHL_JSON/1.3.12.2.1107.5.1.4.11029.30000011102507350176500001989.json', '/home/deeplearning/AHL/AHL_Validated_DICOM/13011102161001/pet2/1.3.12.2.1107.5.1.4.11029.30000011102507350176500001989', '13011102161001', '2.16.840.1.113669.632.20.689996.10000277931', 'PET2', 'SIEMENS', 'PT', 'BQML', 'Undefined', 'START', '20111025', '101612.484000', '20111025', '104058.343000']\n['/home/deeplearning/AHL/AHL_JSON/1.3.12.2.1107.5.6.1.10011.30000014052616572945300000000.json', '/home/deeplearning/AHL/AHL_Validated_DICOM/53011101871014/PET4/imagys_AHL2011_53011101871014_2368bc2e-9601-4a27-9390-3ccdd3e552f3', '53011101871014', '1.2.250.1.38.2.1.102.140425142507.103223883', 'PET4', 'CPS', 'PT', 'BQML', 'Undefined', 'START', '20140526', '181118.734000', '20140526', '185729.000000']\n['/home/deeplearning/AHL/AHL_JSON/1.3.12.2.1107.5.1.4.11061.30000013051008180390600012847.json', '/home/deeplearning/AHL/AHL_Validated_DICOM/13011101251022/pet0/1.3.12.2.1107.5.1.4.11061.30000013051008180390600012847/1.3.12.2.1107.5.1.4.11061.30000013051008180390600012847', '13011101251022', '1.2.840.113711.493413733.8840.394366011.26.1479325270.12', 'PET0', 'SIEMENS', 'PT', 'BQML', 'Undefined', 'START', '20130510', '123514.999995', '20130510', '123515.000000']\n"
     ]
    }
   ],
   "source": [
    "for serie in PT_series : \n",
    "    series_date = serie[-2] \n",
    "    series_time = serie[-1]\n",
    "\n",
    "    acqui_date = serie[-4]\n",
    "    acqui_time = serie[-3]\n",
    "\n",
    "    series_datetime = series_date + series_time\n",
    "    acqui_datetime = acqui_date + acqui_time\n",
    "\n",
    "    parse_serie = parse_datetime(series_datetime)\n",
    "    parse_acquistion = parse_datetime(acqui_datetime)\n",
    "\n",
    "    #print(parse_serie)\n",
    "    #print(parse_acquistion)\n",
    "\n",
    "    if (parse_acquistion - parse_serie).total_seconds() < 0 : \n",
    "        print(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "/home/deeplearning/AHL/AHL_JSON/1.3.12.2.1107.5.1.4.11061.30000013051008180390600012847.json\n",
      "[\"1.0\", \"0.0\", \"0.0\", \"0.0\", \"1.0\", \"0.0\"]\n",
      "EXPORT NIFTI PT\n"
     ]
    }
   ],
   "source": [
    "from library_dicom.dicom_processor.model.SeriesPT import SeriesPT\n",
    "nifti_directory = '/home/deeplearning/AHL/suv_test'\n",
    "dataset = [['/home/deeplearning/AHL/AHL_JSON/1.3.12.2.1107.5.1.4.11061.30000013051008180390600012847.json', '/home/deeplearning/AHL/AHL_Validated_DICOM/13011101251022/pet0/1.3.12.2.1107.5.1.4.11061.30000013051008180390600012847/1.3.12.2.1107.5.1.4.11061.30000013051008180390600012847', '13011101251022', '1.2.840.113711.493413733.8840.394366011.26.1479325270.12', 'PET0', 'SIEMENS', 'PT', 'BQML', 'Undefined', 'START', '20130510', '123514.999995', '20130510', '123515.000000']]\n",
    "\n",
    "\n",
    "error = []\n",
    "for serie in dataset : \n",
    "    print(dataset.index(serie))\n",
    "    print(serie[0])\n",
    "    try : \n",
    "                serie_pt_objet = SeriesPT(serie[1]) \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    " \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error.append(serie)"
   ]
  }
 ]
}