{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from library_dicom.dicom_processor.model.Series import Series \n",
    "from library_dicom.dicom_processor.model.SeriesPT import SeriesPT\n",
    "from library_dicom.dicom_processor.model.SeriesCT import SeriesCT\n",
    "from library_dicom.dicom_processor.model.csv_reader.MaskBuilder import MaskBuilder\n",
    "from library_dicom.dicom_processor.model.FusionPET_CT import FusionPET_CT\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "\n",
    "from library_dicom.dicom_processor.tools.create_mip import *\n",
    "from library_dicom.dicom_processor.tools.threshold_mask import *\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIST FROM PARSE_FILTERED_DICOM_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LIST_PATH from json\n",
    "json_path = '/media/oncopole/DD 2To/REMARC_Validated_DICOMS/REMARC_dataset.json'\n",
    "dataset = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        dataset.append(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of study :  202\n"
     ]
    }
   ],
   "source": [
    "number_of_study = len(dataset)\n",
    "print(\"number of study : \", number_of_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD CSV FILE "
   ]
  },
  {
   "source": [
    "#add csv_file from csv \n",
    "\n",
    "csv_path= '/home/deeplearning/AHL/AHL_CSV_DATA/pet0.csv'\n",
    "csv_file = []\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ';') #liste pour chaque ligne \n",
    "    csv_file = []\n",
    "    for row in reader :\n",
    "        csv_file.append(row)\n",
    "        \n",
    "del csv_file[0] #enlever premi√®re ligne"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add csv_file from a list \n",
    "\n",
    "csv_path = '/media/oncopole/DD 2To/REMARC_csv'\n",
    "liste_csv_file = os.listdir(csv_path)\n",
    "liste_csv = []\n",
    "for csv_file in liste_csv_file : \n",
    "    liste_csv.append(os.path.join(csv_path, csv_file))\n",
    "\n",
    "\n",
    "\n",
    "for data in dataset : \n",
    "    for csv_f in liste_csv : \n",
    "        if data[-1] in csv_f : \n",
    "            data.append(csv_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "check_csv = []\n",
    "for data in dataset : \n",
    "    if len(data) != 8 : \n",
    "        check_csv.append(data)\n",
    "\n",
    "print(len(check_csv))\n",
    "write_json_file('/media/oncopole/DD 2To/REMARC_Validated_DICOMS', 'check_csv', check_csv)\n",
    "\n",
    "for r in check_csv : \n",
    "    dataset.remove(r)"
   ]
  },
  {
   "source": [
    "#rewrite path \n",
    "\n",
    "for data in dataset : \n",
    "    new_1 = data[0].replace('DD 2To', '83c5223d-7a01-4ed0-b268-b877a7da96e2')\n",
    "    new_2 = data[2].replace('DD 2To', '83c5223d-7a01-4ed0-b268-b877a7da96e2')\n",
    "    data[0] = new_1\n",
    "    data[2] = new_2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nombre de study :  182\n"
     ]
    }
   ],
   "source": [
    "print('Nombre de study : ', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_file('/media/oncopole/DD 2To/REMARC_Validated_DICOMS', 'validated_dataset', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove remove_bi_file if it exists in every serie \n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "directory_validated_dicom = ''\n",
    "paths = get_series_path(directory_validated_dicom)\n",
    "\n",
    "for path in paths : \n",
    "    remove_bi_file(path)"
   ]
  },
  {
   "source": [
    "#Check if there is Unconstant Spacing error in every serie of the dataset \n",
    "unconstant_spacing = []\n",
    "serie_error = []\n",
    "for serie in dataset : \n",
    "    print(dataset.index(serie))\n",
    "    try : \n",
    "        if serie[1] =='PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            if serie_pt_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing PET\")\n",
    "                unconstant_spacing.append(serie)\n",
    "            \n",
    "            serie_ct_objet = SeriesCT(serie[2])\n",
    "            nifti_array_ct = serie_ct_objet.get_numpy_array()\n",
    "            if serie_ct_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing CT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            if serie_pt_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing PT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "            serie_ct_objet = SeriesCT(serie[0])\n",
    "            nifti_array_ct = serie_ct_objet.get_numpy_array()\n",
    "            if serie_ct_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing CT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        serie_error.append(serie)\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Careful : maybe need to rewrite path if the series are in an other folder"
   ]
  },
  {
   "source": [
    "#Generate PET, CT, MASK NIFTI with checking suv_max, mean and sd\n",
    "\n",
    "target_size = (128, 128, 256)\n",
    "target_spacing = (4.0, 4.0, 4.0)\n",
    "target_direction = (1,0,0,0,1,0,0,0,1)\n",
    "\n",
    "nifti_directory = '/media/oncopole/DD 2To/REMARC_NIFTI'\n",
    "mip_directory = '/media/oncopole/DD 2To/REMARC_MIP'\n",
    "\n",
    "#save serie_path with false mask \n",
    "serie_false_mask = []\n",
    "#save result about serie with false mask \n",
    "results_false_mask = []\n",
    "#save path of MIP to generate PDF \n",
    "path_mip = []\n",
    "\n",
    "#save error serie \n",
    "error_dataset = []\n",
    "\n",
    "for serie in dataset: \n",
    "    try : \n",
    "        print(dataset.index(serie))\n",
    "        subliste = []\n",
    "        if serie[1] == 'PT' : \n",
    "            \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "            threshold = mask_objet.details_rois['SUVlo']\n",
    "\n",
    "            if mask_objet.is_correct_suv(nifti_array) == True : \n",
    "\n",
    "                print(\"MASK CORRECT\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[2])\n",
    "                serie_ct_objet.get_instances_ordered()\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                #generation nifti mask\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "                #generation merged PT/CT\n",
    "                filename_merged = study_uid+'_'+'nifti_'+'merged'+'.nii'\n",
    "                fusion_objet = FusionPET_CT(serie_pt_objet, serie_ct_objet, target_size, target_spacing, target_direction)\n",
    "                pet_img, ct_img = fusion_objet.generate_pet_ct_img()\n",
    "                merged_img = fusion_objet.save_nifti_fusion(pet_img, ct_img, os.path.join(nifti_directory, filename_merged), mode ='head')\n",
    "                print(\"EXPORT NIFTI MERGED\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            else : \n",
    "                results = []\n",
    "                print(\"FALSE MASK\")\n",
    "                serie_false_mask.append(serie)\n",
    "\n",
    "                print(mask_objet.calcul_suv(nifti_array))\n",
    "                results.append(mask_objet.calcul_suv(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_max(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_max(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_mean(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_mean(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_SD(nifti_array))\n",
    "                results.append(mask_objet.ecart_SD(nifti_array))\n",
    "\n",
    "                results_false_mask.append(results)\n",
    "\n",
    "                #threshold mask 41% \n",
    "                mask_4D = threshold_matrix(mask_4D, nifti_array, 0.41)\n",
    "\n",
    "                #create mip for false mask and check \n",
    "                #pet\n",
    "                angle_filename = mip_projection(nifti_array, 0, mip_directory, study_uid, 'pet', cmap='Greys', vmin=0, vmax=7) \n",
    "                subliste.append(angle_filename)\n",
    "                print('MIP PET')\n",
    "                #mask\n",
    "                angle_filename_mask = mip_projection_4D(mask_4D, 0, mip_directory, study_uid, number_roi, cmap='Greys')\n",
    "                subliste.append(angle_filename_mask)\n",
    "                print('MIP MASK')\n",
    "                path_mip.append(subliste)\n",
    "\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "            threshold = mask_objet.details_rois['SUVlo']\n",
    "\n",
    "            if mask_objet.is_correct_suv(nifti_array) == True :  \n",
    "                print(\"MASK CORRECT\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[0])\n",
    "                serie_ct_objet.get_instances_ordered()\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                #generation nifti mask\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "                #generation merged PT/CT\n",
    "                filename_merged = study_uid+'_'+'nifti_'+'merged'+'.nii'\n",
    "                fusion_objet = FusionPET_CT(serie_pt_objet, serie_ct_objet, target_size, target_spacing, target_direction)\n",
    "                pet_img, ct_img = fusion_objet.generate_pet_ct_img()\n",
    "                merged_img = fusion_objet.save_nifti_fusion(pet_img, ct_img, os.path.join(nifti_directory, filename_merged), mode ='head')\n",
    "                print(\"EXPORT NIFTI MERGED\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            else : \n",
    "                results = []\n",
    "                print(\"FALSE MASK\")\n",
    "                serie_false_mask.append(serie)\n",
    "\n",
    "                print(mask_objet.calcul_suv(nifti_array))\n",
    "                results.append(mask_objet.calcul_suv(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_max(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_max(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_mean(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_mean(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_SD(nifti_array))\n",
    "                results.append(mask_objet.ecart_SD(nifti_array))\n",
    "\n",
    "                results_false_mask.append(results)\n",
    "\n",
    "                #threshold mask 41% \n",
    "                mask_4D = threshold_matrix(mask_4D, nifti_array, 0.41)\n",
    "\n",
    "                #create mip for false mask and check \n",
    "                #pet\n",
    "                angle_filename = mip_projection(nifti_array, 0, mip_directory, study_uid, 'pet', cmap='Greys', vmin=0, vmax=7) \n",
    "                subliste.append(angle_filename)\n",
    "                print(\"MIP PET\")\n",
    "                #mask\n",
    "                angle_filename_mask = mip_projection_4D(mask_4D, 0, mip_directory, study_uid, number_roi, cmap='Greys')\n",
    "                subliste.append(angle_filename_mask)\n",
    "                print('MIP MASK ')\n",
    "                path_mip.append(subliste)\n",
    "               \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error_dataset.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7\n",
      "FALSE MASK\n",
      "{1: {'SUV_max': 27.06, 'SUV_mean': 16.41, 'SD': 4.16}, 2: {'SUV_max': 25.35, 'SUV_mean': 15.83, 'SD': 4.0}, 3: {'SUV_max': 6.41, 'SUV_mean': 4.06, 'SD': 1.09}, 4: {'SUV_max': 3.88, 'SUV_mean': 3.03, 'SD': 0.31}, 5: {'SUV_max': 5.13, 'SUV_mean': 3.2, 'SD': 0.67}, 6: {'SUV_max': 6.11, 'SUV_mean': 3.56, 'SD': 1.02}, 7: {'SUV_max': 28.64, 'SUV_mean': 18.34, 'SD': 3.91}, 8: {'SUV_max': 22.74, 'SUV_mean': 13.96, 'SD': 3.06}, 9: {'SUV_max': 10.32, 'SUV_mean': 6.18, 'SD': 1.73}, 10: {'SUV_max': 18.85, 'SUV_mean': 11.2, 'SD': 2.86}, 11: {'SUV_max': 5.31, 'SUV_mean': 3.49, 'SD': 0.75}, 12: {'SUV_max': 21.28, 'SUV_mean': 13.47, 'SD': 3.39}, 13: {'SUV_max': 23.71, 'SUV_mean': 14.31, 'SD': 3.4}, 14: {'SUV_max': 26.68, 'SUV_mean': 17.75, 'SD': 4.34}, 15: {'SUV_max': 28.16, 'SUV_mean': 17.31, 'SD': 3.93}, 16: {'SUV_max': 8.1, 'SUV_mean': 4.85, 'SD': 1.29}, 17: {'SUV_max': 4.71, 'SUV_mean': 3.1, 'SD': 0.45}, 18: {'SUV_max': 25.67, 'SUV_mean': 17.2, 'SD': 3.62}, 19: {'SUV_max': 27.49, 'SUV_mean': 17.96, 'SD': 4.57}, 20: {'SUV_max': 28.85, 'SUV_mean': 18.85, 'SD': 4.23}, 21: {'SUV_max': 26.06, 'SUV_mean': 17.07, 'SD': 3.98}, 22: {'SUV_max': 4.43, 'SUV_mean': 2.91, 'SD': 0.65}, 23: {'SUV_max': 9.36, 'SUV_mean': 5.98, 'SD': 1.67}, 24: {'SUV_max': 4.52, 'SUV_mean': 2.79, 'SD': 0.59}, 25: {'SUV_max': 4.43, 'SUV_mean': 2.77, 'SD': 0.65}, 26: {'SUV_max': 8.95, 'SUV_mean': 5.21, 'SD': 1.51}}\n",
      "[]\n",
      "[20, 'POLYGON', 0.14999999999999858]\n",
      "[]\n",
      "MIP PET\n",
      "MIP MASK\n"
     ]
    }
   ]
  },
  {
   "source": [
    "print(\"number of error : \", len(error_dataset))\n",
    "print(\"number of false mask : \" , len(serie_false_mask))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save different json \n",
    "directory_nifti = ''\n",
    "write_json_file(directory_nifti, 'false_mask_serie', serie_false_mask)\n",
    "write_json_file(directory_nifti, 'false_mask_results', results_false_mask)\n",
    "\n",
    "write_json_file(directory_nifti, 'error', error_dataset)\n",
    "\n",
    "mip directory = directory_nifti+'/'+'MIP'\n",
    "write_json_file(mip_directory, 'path_mip', path_mip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pdf of MIP for false mask \n",
    "filename = os.path.join(mip_directory, 'list_mip_dataset.pdf')\n",
    "create_pdf_mip(path_mip, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#Generate PET, CT, MASK NIFTI without checking\n",
    "\n",
    "nifti_directory = nifti_directory = '/home/deeplearning/AHL/AHL_NIFTI'\n",
    "\n",
    "error_dataset = []\n",
    "\n",
    "for serie in dataset: \n",
    "    try : \n",
    "        print(dataset.index(serie))\n",
    "\n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "\n",
    "            print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "            print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                    #generation nifti CT\n",
    "            serie_ct_objet = SeriesCT(serie[2])\n",
    "            serie_ct_objet.get_numpy_array()\n",
    "            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "            print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                    #generation nifti mask\n",
    "            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "            print(\"EXPORT NIFTI MASK\")\n",
    "          \n",
    "          \n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "            number_roi = mask_4D.shape[3]\n",
    "\n",
    "            print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "            print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                     #generation nifti CT\n",
    "            serie_ct_objet = SeriesCT(serie[0])\n",
    "            serie_ct_objet.get_numpy_array()\n",
    "            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "            print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                    #generation nifti mask\n",
    "            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "            print(\"EXPORT NIFTI MASK\")\n",
    "           \n",
    "    except Exception as err : \n",
    "        print(err)\n",
    "        print(serie)\n",
    "        error_dataset.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#Generate PET & CT NIFTI only\n",
    "\n",
    "nifti_directory = '/home/deeplearning/AHL/AHL_NIFTI/pet4'\n",
    "\n",
    "error = []\n",
    "for serie in pet_4 : \n",
    "    print(pet_4.index(serie))\n",
    "    try : \n",
    "        if serie[1] == 'PT' : \n",
    "                serie_pt_objet = SeriesPT(serie[0]) \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[2])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "        else : \n",
    "                serie_pt_objet = SeriesPT(serie[2]) \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                        \n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[0])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    " \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate PET only\n",
    "\n",
    "nifti_directory = '/home/deeplearning/AHL/suv_test'\n",
    "dataset = dataset[0:10]\n",
    "\n",
    "error = []\n",
    "for serie in dataset : \n",
    "    print(dataset.index(serie))\n",
    "    print(serie[0])\n",
    "    try : \n",
    "                serie_pt_objet = SeriesPT(serie[1]) \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    " \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error.append(serie)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}