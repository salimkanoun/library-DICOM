{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from library_dicom.dicom_processor.model.Series import Series \n",
    "from library_dicom.dicom_processor.model.SeriesPT import SeriesPT\n",
    "from library_dicom.dicom_processor.model.SeriesCT import SeriesCT\n",
    "from library_dicom.dicom_processor.model.csv_reader.MaskBuilder import MaskBuilder\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "\n",
    "from library_dicom.dicom_processor.tools.create_mip import *\n",
    "from library_dicom.dicom_processor.tools.threshold_mask import *\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIST FROM PARSE_FILTERED_DICOM_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LIST_PATH from json\n",
    "json_path = '/home/deeplearning/AHL/AHL_new_dataset.json'\n",
    "dataset = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        dataset.append(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_study = len(dataset)\n",
    "print(\"number of study : \", number_of_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add csv_file to dataset \n",
    "\n",
    "csv_path= '/home/deeplearning/AHL/AHL_CSV_DATA/pet0.csv'\n",
    "csv_file = []\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ';') #liste pour chaque ligne \n",
    "    csv_file = []\n",
    "    for row in reader :\n",
    "        csv_file.append(row)\n",
    "        \n",
    "del csv_file[0] #enlever premi√®re ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset : \n",
    "    uid = data[-3]\n",
    "\n",
    "    for row in csv_file: \n",
    "        if uid in row : \n",
    "            data.append(os.path.join( '/home/deeplearning/AHL/AHL_CSV_DATA', row[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pet2 & pet 4 \n",
    "\n",
    "pet_2 = []\n",
    "pet_4 = []\n",
    "for data in dataset : \n",
    "    if 'pet2' in data[5].lower():\n",
    "        pet_2.append(data)\n",
    "\n",
    "for data in dataset : \n",
    "    if 'pet4' in data[5].lower():\n",
    "        pet_4.append(data)\n",
    "\n",
    "\n",
    "print(len(pet_2))\n",
    "print(len(pet_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove PET 2 and PET 4\n",
    "remove_study = []\n",
    "for data in dataset : \n",
    "    if len(data) != 8 : \n",
    "        remove_study.append(data)\n",
    "\n",
    "for r in remove_study : \n",
    "    dataset.remove(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de study : ', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove remove_bi_file if it exists in every serie \n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "directory_validated_dicom = ''\n",
    "paths = get_series_path(directory_validated_dicom)\n",
    "\n",
    "for path in paths : \n",
    "    remove_bi_file(path)"
   ]
  },
  {
   "source": [
    "#Check if there is Unconstant Spacing error in every serie of the dataset \n",
    "unconstant_spacing = []\n",
    "serie_error = []\n",
    "for serie in dataset : \n",
    "    print(dataset.index(serie))\n",
    "    try : \n",
    "        if serie[1] =='PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            if serie_pt_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing PET\")\n",
    "                unconstant_spacing.append(serie)\n",
    "            \n",
    "            serie_ct_objet = SeriesCT(serie[2])\n",
    "            nifti_array_ct = serie_ct_objet.get_numpy_array()\n",
    "            if serie_ct_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing CT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            if serie_pt_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing PT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "            serie_ct_objet = SeriesCT(serie[0])\n",
    "            nifti_array_ct = serie_ct_objet.get_numpy_array()\n",
    "            if serie_ct_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing CT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        serie_error.append(serie)\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Careful : maybe need to rewrite path if the series are in an other folder"
   ]
  },
  {
   "source": [
    "#Generate PET, CT, MASK NIFTI with checking suv_max, mean and sd\n",
    "\n",
    "nifti_directory = '/home/deeplearning/AHL/AHL_NIFTI'\n",
    "mip_directory = '/home/deeplearning/AHL/AHL_MIP'\n",
    "\n",
    "#save serie_path with false mask \n",
    "serie_false_mask = []\n",
    "#save result about serie with false mask \n",
    "results_false_mask = []\n",
    "#save path of MIP to generate PDF \n",
    "path_mip = []\n",
    "\n",
    "#save error serie \n",
    "error_dataset = []\n",
    "\n",
    "for serie in dataset: \n",
    "    try : \n",
    "        print(dataset.index(serie))\n",
    "        subliste = []\n",
    "        if serie[1] == 'PT' : \n",
    "            \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "            threshold = mask_objet.details_rois['SUVlo']\n",
    "\n",
    "            if mask_objet.is_correct_suv(nifti_array) == True :  \n",
    "                print(\"MASK CORRECT\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[2])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                #generation nifti mask\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "\n",
    "            else : \n",
    "                results = []\n",
    "                print(\"FALSE MASK\")\n",
    "                serie_false_mask.append(serie)\n",
    "\n",
    "                print(mask_objet.calcul_suv(nifti_array))\n",
    "                results.append(mask_objet.calcul_suv(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_max(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_max(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_mean(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_mean(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_SD(nifti_array))\n",
    "                results.append(mask_objet.ecart_SD(nifti_array))\n",
    "\n",
    "                results_false_mask.append(results)\n",
    "\n",
    "                #threshold mask with threshold in csv file  \n",
    "                mask_4D = threshold_mask(mask_4D, mask_objet.details_rois, nifti_array)\n",
    "                #create mip for false mask and check \n",
    "                angle_filename = mip_projection(nifti_array, 0, mip_directory, study_uid, 'pet', cmap='Greys', vmin = 0, vmax = 7) \n",
    "                subliste.append(angle_filename)\n",
    "                angle_filename_mask = mip_projection_4D(mask_4D, 0, mip_directory, study_uid, number_roi, cmap='Greys', borne_max = 1.0)\n",
    "                subliste.append(angle_filename_mask)\n",
    "                path_mip.append(subliste)\n",
    "\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "            number_roi = mask_4D.shape[3]\n",
    "            threshold = mask_objet.details_rois['SUVlo']\n",
    "\n",
    "            if mask_objet.is_correct_suv(nifti_array) == True : \n",
    "                print(\"MASK CORRECT\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[0])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                #generation nifti mask\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "            else : \n",
    "                print(\"FALSE MASK\")\n",
    "                serie_false_mask.append(serie)\n",
    "\n",
    "                print(mask_objet.calcul_suv(nifti_array))\n",
    "                results.append(mask_objet.calcul_suv(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_max(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_max(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_mean(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_mean(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_SD(nifti_array))\n",
    "                results.append(mask_objet.ecart_SD(nifti_array))\n",
    "\n",
    "                results_false_mask.append(results)\n",
    "\n",
    "                #threshold mask with threshold in csv \n",
    "                mask_4D = threshold_mask(mask_4D, mask_objet.details_rois, nifti_array)\n",
    "                #create mip for false mask and check \n",
    "                angle_filename = mip_projection(nifti_array, 0, mip_directory, study_uid, 'pet', cmap='Greys', vmin = 0, vmax = 7) \n",
    "                subliste.append(angle_filename)\n",
    "                angle_filename_mask = mip_projection_4D(mask_4D, 0, mip_directory, study_uid, number_roi, cmap='Greys', borne_max = 1.0)\n",
    "                subliste.append(angle_filename_mask)\n",
    "                path_mip.append(subliste)\n",
    "               \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error_dataset.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "print(\"number of error : \", len(error_dataset))\n",
    "print(\"number of false mask : \" , len(serie_false_mask))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save different json \n",
    "directory_nifti = ''\n",
    "write_json_file(directory_nifti, 'false_mask_serie', serie_false_mask)\n",
    "write_json_file(directory_nifti, 'false_mask_results', results_false_mask)\n",
    "\n",
    "write_json_file(directory_nifti, 'error', error_dataset)\n",
    "\n",
    "mip directory = directory_nifti+'/'+'MIP'\n",
    "write_json_file(mip_directory, 'path_mip', path_mip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pdf of MIP for false mask \n",
    "filename = os.path.join(mip_directory, 'list_mip_dataset.pdf')\n",
    "create_pdf_mip(path_mip, filename)"
   ]
  },
  {
   "source": [
    "#Generate PET, CT, MASK NIFTI without checking\n",
    "\n",
    "nifti_directory = nifti_directory = '/home/deeplearning/AHL/AHL_NIFTI'\n",
    "\n",
    "error_dataset = []\n",
    "\n",
    "for serie in dataset: \n",
    "    try : \n",
    "        print(dataset.index(serie))\n",
    "\n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "\n",
    "            print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "            print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                    #generation nifti CT\n",
    "            serie_ct_objet = SeriesCT(serie[2])\n",
    "            serie_ct_objet.get_numpy_array()\n",
    "            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "            print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                    #generation nifti mask\n",
    "            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "            print(\"EXPORT NIFTI MASK\")\n",
    "          \n",
    "          \n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "            number_roi = mask_4D.shape[3]\n",
    "\n",
    "            print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "            print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                     #generation nifti CT\n",
    "            serie_ct_objet = SeriesCT(serie[0])\n",
    "            serie_ct_objet.get_numpy_array()\n",
    "            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "            print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                    #generation nifti mask\n",
    "            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mask_4D)\n",
    "            print(\"EXPORT NIFTI MASK\")\n",
    "           \n",
    "    except Exception as err : \n",
    "        print(err)\n",
    "        print(serie)\n",
    "        error_dataset.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#Generate PET & CT NIFTI only\n",
    "\n",
    "nifti_directory = '/home/deeplearning/AHL/AHL_NIFTI/pet4'\n",
    "\n",
    "error = []\n",
    "for serie in pet_4 : \n",
    "    print(pet_4.index(serie))\n",
    "    try : \n",
    "        if serie[1] == 'PT' : \n",
    "                serie_pt_objet = SeriesPT(serie[0]) \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[2])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "        else : \n",
    "                serie_pt_objet = SeriesPT(serie[2]) \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                        \n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[0])\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct))\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    " \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate PET only\n",
    "\n",
    "nifti_directory = '/home/deeplearning/AHL/suv_test'\n",
    "dataset = dataset[0:10]\n",
    "\n",
    "error = []\n",
    "for serie in dataset : \n",
    "    print(dataset.index(serie))\n",
    "    print(serie[0])\n",
    "    try : \n",
    "                serie_pt_objet = SeriesPT(serie[1]) \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt))\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    " \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error.append(serie)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}