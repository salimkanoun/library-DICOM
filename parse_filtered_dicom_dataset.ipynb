{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "from library_dicom.dicom_processor.tools.series import get_series_object\n",
    "\n",
    "import csv\n",
    "from library_dicom.dicom_processor.model.Series import Series"
   ]
  },
  {
   "source": [
    "#### - Get every serie paths and generate JSON file "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_paths = get_series_path('/media/oncopole/DD 2To/REMARC_Validated_DICOM')\n",
    "export_folder = '/media/oncopole/DD 2To/REMARC_JSON'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_problem = []\n",
    "for serie_path in series_paths:\n",
    "    print(series_paths.index(serie_path))\n",
    "    try:\n",
    "        dicom_serie = get_series_object(serie_path)\n",
    "        dicomsInfo = dicom_serie.get_series_details()\n",
    "        write_json_file(export_folder, dicomsInfo['series']['SeriesInstanceUID'], dicomsInfo)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(dicomsInfo)\n",
    "        index_problem.append(series_paths.index(serie_path))"
   ]
  },
  {
   "source": [
    "#### - Get list of every json "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = export_folder\n",
    "list_dir_json = os.listdir(json_path)\n",
    "list_json = []\n",
    "for file_ in list_dir_json : \n",
    "    list_json.append([os.path.join(json_path, file_)])"
   ]
  },
  {
   "source": [
    "#### - Get informations from every json in list "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for liste in list_json : \n",
    "    print(list_json.index(liste))\n",
    "    with open(liste[0]) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "\n",
    "        patient_id = reader[\"patient\"][\"PatientID\"]\n",
    "        study_uid = reader[\"study\"]['StudyInstanceUID']\n",
    "        modal = reader['series']['Modality']\n",
    "\n",
    "        path = reader['path']\n",
    "\n",
    "        type_ = reader['study'][\"AccessionNumber\"]\n",
    "\n",
    "        liste.append(path)\n",
    "        liste.append(modal)\n",
    "        liste.append(type_)\n",
    "        liste.append(patient_id)\n",
    "        liste.append(study_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_json[0]"
   ]
  },
  {
   "source": [
    "#### - Reunite CT/PT series with same study uid "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get every study_uid \n",
    "stud = []\n",
    "for liste in list_json : \n",
    "    stud.append(liste[-1])\n",
    "\n",
    "study_uid = []\n",
    "study_uid.append(stud[0])\n",
    "for uid in stud : \n",
    "    if uid not in study_uid : \n",
    "        study_uid.append(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de study :', len(study_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for uid in study_uid : \n",
    "    sub = []\n",
    "    for liste in list_json : \n",
    "        if uid in liste : \n",
    "            sub.append(liste)\n",
    "    data.append(sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for serie in data : \n",
    "    serie[0].append(serie[1][0])\n",
    "    serie[0].append(serie[1][1])\n",
    "    serie[0].append(serie[1][2])\n",
    "\n",
    "    dataset.append(serie[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Clean dataset : if there is no json, double study_uid, if not CT AND PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no json \n",
    "i = 0\n",
    "no_json_liste = []\n",
    "for data in dataset : \n",
    "    if len(data) != 9 : \n",
    "        i += 1 \n",
    "        no_json_liste.append(data)\n",
    "\n",
    "if i != 0 : \n",
    "    print(\"number of study with no json : {}\".format(i))\n",
    "\n",
    "    for no_json_file in no_json_liste : \n",
    "        no_json_liste.remove(no_json_file)\n",
    "\n",
    "    print(\"dataset cleaned \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double study_uid \n",
    "double = []\n",
    "double.append(dataset[0])\n",
    "for data in dataset : \n",
    "    if data not in double : \n",
    "        double.append(data)\n",
    "\n",
    "if len(double) == len(dataset) : \n",
    "    print('No double study uid, dataset cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Modality \n",
    "index = []\n",
    "for data in dataset : \n",
    "    modal = []\n",
    "    modal.append(data[2])\n",
    "    modal.append(data[-1])\n",
    "    #print(modal)\n",
    "    if modal[0] == modal[1] : \n",
    "        index.append(dataset.index(data))\n",
    "#print(index)\n",
    "#if index is not empty : \n",
    "if len(index) != 0 :\n",
    "    liste_to_remove = []\n",
    "    for ind in index : \n",
    "        liste_to_remove.append(dataset[ind])\n",
    "\n",
    "    for r in liste_to_remove : \n",
    "        dataset.remove(r)\n",
    "\n",
    "print(\"dataset cleaned\")"
   ]
  },
  {
   "source": [
    "#### - Prepare json file to generate nifti in \"nifti_builder_from_json.ipynb\" script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_results = []\n",
    "for liste in dataset : \n",
    "    subliste = []\n",
    "    subliste.append(liste[1]) #path_1\n",
    "    subliste.append(liste[2]) #modal 1\n",
    "    subliste.append(liste[-2]) #path_2\n",
    "    subliste.append(liste[-1]) #modal_2\n",
    "    subliste.append(liste[5]) #study_uid\n",
    "    subliste.append(liste[3]) #type\n",
    "    subliste.append(liste[4]) #patient id\n",
    "\n",
    "    study_results.append(subliste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results as json \n",
    "directory = '/media/oncopole/DD 2To/REMARC_Validated_DICOM'\n",
    "filename = 'REMARC_dataset'\n",
    "write_json_file(directory, filename, study_results)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6a0b6c04207aa6f5c33e08335e377a5793c5a1abe8e179f13df17cfd923ec7d1"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}