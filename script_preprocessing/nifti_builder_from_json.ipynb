{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from library_dicom.dicom_processor.model.Series import Series \n",
    "from library_dicom.dicom_processor.model.SeriesPT import SeriesPT\n",
    "from library_dicom.dicom_processor.model.SeriesCT import SeriesCT\n",
    "from library_dicom.dicom_processor.model.csv_reader.MaskBuilder import MaskBuilder\n",
    "from library_dicom.dicom_processor.model.csv_reader.CsvReader import CsvReader\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "from library_dicom.dicom_processor.tools.create_mip import *\n",
    "from library_dicom.dicom_processor.tools.threshold_mask import *\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import csv"
   ]
  },
  {
   "source": [
    "#### - Get dataset from  PARSE_FILTERED_DICOM_DATASET script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LIST_PATH from json\n",
    "json_path = '/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/pvab/dataset.json'\n",
    "dataset = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        dataset.append(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of study :  3\n"
     ]
    }
   ],
   "source": [
    "number_of_study = len(dataset)\n",
    "print(\"number of study : \", number_of_study)"
   ]
  },
  {
   "source": [
    "#### - Add CSV file for every study on the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#add csv_file from csv \n",
    "\n",
    "csv_path= '/media/deeplearning/LACIE SHARE/AHL_NIFTI/pet0.csv'\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ';') #liste pour chaque ligne \n",
    "    csv_file = []\n",
    "    for row in reader :\n",
    "        csv_file.append(row)\n",
    "        \n",
    "del csv_file[0] #enlever premi√®re ligne\n",
    "csv_directory = '/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/AHL/AHL2011_CSV_DATA/AHL2011-CSV'\n",
    "for data in dataset : \n",
    "    study_uid = data[-1]\n",
    "    for row in csv_file : \n",
    "        if study_uid == row[1] : \n",
    "            data.append(os.path.join(csv_directory, row[4]))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#add csv_file from a list \n",
    "csv_paths = get_series_path('/media/oncopole/LACIE SHARE/PVAB/PVAB_csv')\n",
    "liste_csv = []\n",
    "for csv_path in csv_paths : \n",
    "    csv_file_ = os.listdir(csv_path)[0]\n",
    "    #print(csv_file_)\n",
    "    liste_csv.append(os.path.join(csv_path, csv_file_))\n",
    "\n",
    "\n",
    "#print(liste_csv)\n",
    "\n",
    "\n",
    "for data in dataset : \n",
    "    patient_id = data[-1]\n",
    "    for csv_file in liste_csv: \n",
    "        if patient_id in csv_file: \n",
    "            data.append(csv_file)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#### - Verify if every study has a csv file, \n",
    "####            If not, write a json , remove study from dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "no_csv = []\n",
    "for data in dataset : \n",
    "    if len(data) != 8 : \n",
    "        no_csv.append(data)\n",
    "print(\"Nbr de study sans csv :\", len(no_csv))\n",
    "\n",
    "try : \n",
    "    for err in no_csv : \n",
    "        dataset.remove(err)\n",
    "except Exception as err : \n",
    "    print(err) \n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE DATASET AS JSON \n",
    "\n",
    "write_json_file('/media/oncopole/LACIE SHARE/PVAB', 'pvab_dataset', dataset)"
   ]
  },
  {
   "source": [
    "#### - Remove remove_bi_file if it exists in every serie "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "directory_validated_dicom = ''\n",
    "paths = get_series_path(directory_validated_dicom)\n",
    "\n",
    "for path in paths : \n",
    "    remove_bi_file(path)"
   ]
  },
  {
   "source": [
    "### Different scripts : "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### - Check if there is Unconstance Spacing error in every study of the dataset "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "unconstant_spacing = []\n",
    "serie_error = []\n",
    "for serie in dataset : \n",
    "    print(dataset.index(serie))\n",
    "    try : \n",
    "        if serie[1] =='PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            if serie_pt_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing PET\")\n",
    "                unconstant_spacing.append(serie)\n",
    "            \n",
    "            serie_ct_objet = SeriesCT(serie[2])\n",
    "            serie_ct_objet.get_instances_ordered()\n",
    "            nifti_array_ct = serie_ct_objet.get_numpy_array()\n",
    "            if serie_ct_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing CT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            if serie_pt_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing PT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "            serie_ct_objet = SeriesCT(serie[0])\n",
    "            serie_ct_objet.get_instances_ordered()\n",
    "            nifti_array_ct = serie_ct_objet.get_numpy_array()\n",
    "            if serie_ct_objet.get_z_spacing =='Unconstant Spacing' :\n",
    "                print(\"Unconstant Spacing CT\")\n",
    "                unconstant_spacing.append(serie)\n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        serie_error.append(serie)\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "####Generate PET, CT, MASK NIFTI with checking suv_max, mean and sd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/media/oncopole/DDArchive/PVAB/pvab_dataset.json'\n",
    "dataset = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        dataset.append(info)\n",
    "\n"
   ]
  },
  {
   "source": [
    "#Generate PET, CT, MASK NIFTI with checking suv_max, mean and sd\n",
    "\n",
    "nifti_directory = '/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/pvab'\n",
    "mip_directory = '/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/pvab'\n",
    "\n",
    "#save serie_path with false mask \n",
    "serie_false_mask = []\n",
    "#save result about serie with false mask \n",
    "results_false_mask = []\n",
    "#save path of MIP to generate PDF \n",
    "path_mip = []\n",
    "\n",
    "#save error serie \n",
    "error_dataset = []\n",
    "\n",
    "for serie in dataset[2:3]: \n",
    "    try : \n",
    "        print(dataset.index(serie))\n",
    "        subliste = []\n",
    "        if serie[1] == 'PT' : \n",
    "            \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            \n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            \n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            \n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "            threshold = mask_objet.details_rois['SUVlo']\n",
    "\n",
    "            if mask_objet.is_correct_suv(nifti_array) == True : \n",
    "\n",
    "                print(\"MASK CORRECT\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt), mode='pet')\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[2])\n",
    "                serie_ct_objet.get_instances_ordered()\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct), mode='ct')\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                #generation nifti mask\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mode='mask', mask=mask_4D)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "\n",
    "            else : \n",
    "                results = []\n",
    "                print(\"FALSE MASK\")\n",
    "                serie_false_mask.append(serie)\n",
    "\n",
    "                print(mask_objet.calcul_suv(nifti_array))\n",
    "                results.append(mask_objet.calcul_suv(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_max(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_max(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_mean(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_mean(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_SD(nifti_array))\n",
    "                results.append(mask_objet.ecart_SD(nifti_array))\n",
    "\n",
    "                results_false_mask.append(results)\n",
    "\n",
    "                #threshold mask 41% \n",
    "                mask_4D = threshold_matrix(mask_4D, nifti_array, 0.41)\n",
    "\n",
    "                #create mip for false mask and check \n",
    "                #pet\n",
    "                angle_filename = mip_projection(nifti_array, 0, mip_directory, study_uid, 'pet', cmap='Greys', vmin=0, vmax=7) \n",
    "                subliste.append(angle_filename)\n",
    "                print('MIP PET')\n",
    "               # mask\n",
    "                angle_filename_mask = mip_projection_4D(mask_4D, 0, mip_directory, study_uid, number_roi, cmap='Greys')\n",
    "                subliste.append(angle_filename_mask)\n",
    "                print('MIP MASK')\n",
    "                path_mip.append(subliste)\n",
    "\n",
    "\n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            \n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            \n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "            threshold = mask_objet.details_rois['SUVlo']\n",
    "\n",
    "            if mask_objet.is_correct_suv(nifti_array) == True :  \n",
    "                print(\"MASK CORRECT\")\n",
    "                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt), mode='pet')\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[0])\n",
    "                serie_ct_objet.get_instances_ordered()\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct), mode='ct')\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                #generation nifti mask\n",
    "                filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mode='mask', mask=mask_4D)\n",
    "                print(\"EXPORT NIFTI MASK\")\n",
    "\n",
    "\n",
    "\n",
    "            else : \n",
    "                results = []\n",
    "                print(\"FALSE MASK\")\n",
    "                serie_false_mask.append(serie)\n",
    "\n",
    "                print(mask_objet.calcul_suv(nifti_array))\n",
    "                results.append(mask_objet.calcul_suv(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_max(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_max(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_suv_mean(nifti_array))\n",
    "                results.append(mask_objet.ecart_suv_mean(nifti_array))\n",
    "\n",
    "                print(mask_objet.ecart_SD(nifti_array))\n",
    "                results.append(mask_objet.ecart_SD(nifti_array))\n",
    "\n",
    "                results_false_mask.append(results)\n",
    "\n",
    "                #threshold mask 41% \n",
    "                mask_4D = threshold_matrix(mask_4D, nifti_array, 0.41)\n",
    "\n",
    "                #create mip for false mask and check \n",
    "                #pet\n",
    "                angle_filename = mip_projection(nifti_array, 0, mip_directory, study_uid, 'pet', cmap='Greys', vmin=0, vmax=7) \n",
    "                subliste.append(angle_filename)\n",
    "                print(\"MIP PET\")\n",
    "                #mask\n",
    "                angle_filename_mask = mip_projection_4D(mask_4D, 0, mip_directory, study_uid, number_roi, cmap='Greys')\n",
    "                subliste.append(angle_filename_mask)\n",
    "                print('MIP MASK ')\n",
    "                path_mip.append(subliste)\n",
    "               \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error_dataset.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n",
      "MASK CORRECT\n",
      "EXPORT NIFTI PT\n",
      "EXPORT NIFTI CT\n"
     ]
    }
   ]
  },
  {
   "source": [
    "print(\"number of error : \", len(error_dataset))\n",
    "print(\"number of false mask : \" , len(serie_false_mask))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#Save different json \n",
    "directory_nifti = 'media/oncopole/LACIE SHARE/PVAB'\n",
    "write_json_file(directory_nifti, 'false_mask_serie', serie_false_mask)\n",
    "#write_json_file(directory_nifti, 'false_mask_results', results_false_mask)\n",
    "write_json_file(directory_nifti, 'error', error_dataset)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "#### - Generate PET, CT, MASK NIFTI without checking"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "nifti_directory = '/media/deeplearning/78ca2911-9e9f-4f78-b80a-848024b95f92/pvab'\n",
    "error_dataset = []\n",
    "\n",
    "for serie in dataset[2:3]: \n",
    "    try : \n",
    "        print(dataset.index(serie))\n",
    "\n",
    "        if serie[1] == 'PT' : \n",
    "            serie_pt_objet = SeriesPT(serie[0])\n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "\n",
    "            number_roi = mask_4D.shape[3]\n",
    "\n",
    "            print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt), mode='pet')\n",
    "            print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                    #generation nifti CT\n",
    "            serie_ct_objet = SeriesCT(serie[2])\n",
    "            serie_ct_objet.get_instances_ordered()\n",
    "            serie_ct_objet.get_numpy_array()\n",
    "            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct), mode='ct')\n",
    "            print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                    #generation nifti mask\n",
    "            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mode='mask', mask=mask_4D)\n",
    "            print(\"EXPORT NIFTI MASK\")\n",
    "          \n",
    "          \n",
    "        else : \n",
    "            serie_pt_objet = SeriesPT(serie[2])\n",
    "            serie_pt_objet.get_instances_ordered()\n",
    "            nifti_array = serie_pt_objet.get_numpy_array()\n",
    "            study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "            size_matrix = serie_pt_objet.get_size_matrix()\n",
    "            mask_objet = MaskBuilder(serie[-1], size_matrix)\n",
    "            mask_4D = mask_objet.mask_array\n",
    "            number_roi = mask_4D.shape[3]\n",
    "\n",
    "            print(\"MASK CORRECT\")\n",
    "                    #generation nifti PT\n",
    "            filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt), mode='pet')\n",
    "            print(\"EXPORT NIFTI PT\")\n",
    "\n",
    "                     #generation nifti CT\n",
    "            serie_ct_objet = SeriesCT(serie[0])\n",
    "            serie_ct_objet.get_instances_ordered()\n",
    "            serie_ct_objet.get_numpy_array()\n",
    "            filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "            serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct), mode='ct')\n",
    "            print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "                    #generation nifti mask\n",
    "            filename_mask = study_uid+'_'+'nifti_'+'mask'+'.nii'\n",
    "            serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_mask), mode='mask', mask=mask_4D)\n",
    "            print(\"EXPORT NIFTI MASK\")\n",
    "           \n",
    "    except Exception as err : \n",
    "        print(err)\n",
    "        print(serie)\n",
    "        error_dataset.append(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of error : \", len(error_dataset))\n",
    "directory_nifti = '/media/oncopole/LACIE SHARE/PVAB'\n",
    "write_json_file(directory_nifti, 'error', error_dataset)"
   ]
  },
  {
   "source": [
    "#### - Generate PET & CT NIFTI only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/media/oncopole/DD 2To/REMARC/REMARC_Validated_DICOM/no_csv.json'\n",
    "dataset = []\n",
    "with open(json_path) as json_file : \n",
    "    reader = json.load(json_file)\n",
    "    for info in reader :\n",
    "        dataset.append(info)"
   ]
  },
  {
   "source": [
    "nifti_directory  = '/media/oncopole/DD 2To/REMARC/NIFTI'\n",
    "\n",
    "error = []\n",
    "for serie in dataset : \n",
    "    print(dataset.index(serie))\n",
    "    try : \n",
    "        if serie[1] == 'PT' : \n",
    "                serie_pt_objet = SeriesPT(serie[0]) \n",
    "                serie_pt_objet.get_instances_ordered()\n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt), mode='pet')\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[2])\n",
    "                serie_ct_objet.get_instances_ordered()\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct), mode='ct')\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    "\n",
    "        else : \n",
    "                serie_pt_objet = SeriesPT(serie[2])\n",
    "                serie_pt_objet.get_instances_ordered() \n",
    "                nifti_array = serie_pt_objet.get_numpy_array()\n",
    "                study_uid = serie_pt_objet.get_series_details()['study']['StudyInstanceUID']\n",
    "\n",
    "                        \n",
    "                                #generation nifti PT\n",
    "                filename_pt = study_uid+'_'+'nifti_'+'PT'+'.nii'\n",
    "                serie_pt_objet.export_nifti(os.path.join(nifti_directory, filename_pt), mode='pet')\n",
    "                print(\"EXPORT NIFTI PT\")\n",
    "                                #generation nifti CT\n",
    "                serie_ct_objet = SeriesCT(serie[0])\n",
    "                serie_ct_objet.get_instances_ordered()\n",
    "                serie_ct_objet.get_numpy_array()\n",
    "                filename_ct = study_uid+'_'+'nifti_'+'CT'+'.nii'\n",
    "                serie_ct_objet.export_nifti(os.path.join(nifti_directory, filename_ct), mode='ct')\n",
    "                print(\"EXPORT NIFTI CT\")\n",
    " \n",
    "\n",
    "    except Exception as err : \n",
    "        print(serie)\n",
    "        print(err)\n",
    "        error.append(serie)                                                                                                                                                                                                                              "
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}