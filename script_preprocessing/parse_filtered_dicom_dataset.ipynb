{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "from library_dicom.dicom_processor.tools.series import get_series_object\n",
    "\n",
    "import csv\n",
    "from library_dicom.dicom_processor.model.Series import Series"
   ]
  },
  {
   "source": [
    "#### - Get every serie paths and generate JSON file "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_paths = get_series_path('/media/deeplearning/LACIE SHARE/good')\n",
    "export_folder = '/media/deeplearning/LACIE SHARE/good/JSON'"
   ]
  },
  {
   "source": [
    "index_problem = []\n",
    "for serie_path in series_paths:\n",
    "    print(series_paths.index(serie_path))\n",
    "    try:\n",
    "        dicom_serie = get_series_object(serie_path)\n",
    "        dicomsInfo = dicom_serie.get_series_details()\n",
    "        write_json_file(export_folder, dicomsInfo['series']['SeriesInstanceUID'], dicomsInfo)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(dicomsInfo)\n",
    "        index_problem.append(series_paths.index(serie_path))"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = export_folder\n",
    "list_dir_json = os.listdir(json_path)\n",
    "list_json = []\n",
    "for file_ in list_dir_json : \n",
    "    list_json.append([os.path.join(json_path, file_)])"
   ]
  },
  {
   "source": [
    "#### - Get informations from every json in list "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for liste in list_json : \n",
    "    #print(list_json.index(liste))\n",
    "    with open(liste[0]) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "\n",
    "        patient_id = reader[\"patient\"][\"PatientID\"]\n",
    "        #patient_id = reader['path'].split('/')[6]\n",
    "        study_uid = reader[\"study\"]['StudyInstanceUID']\n",
    "        modal = reader['series']['Modality']\n",
    "\n",
    "        path = reader['path']\n",
    "\n",
    "        type_ = reader['study'][\"AccessionNumber\"]\n",
    "        #print(type_)\n",
    "        #date = reader['study']['StudyDate']\n",
    "        #name = '_'.join(reader['patient']['PatientName'].split('^')).lower()\n",
    "        liste.append(path)\n",
    "        liste.append(modal)\n",
    "        liste.append(type_)\n",
    "        liste.append(patient_id)\n",
    "        #liste.append(name)\n",
    "        liste.append(study_uid)\n",
    "        #liste.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_json[0]"
   ]
  },
  {
   "source": [
    "#### - Keep only pet0/pet screening "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "not_pet_screening = []\n",
    "for data in list_json : \n",
    "    #print(data[3])\n",
    "    if data[3] != 'PET0' : \n",
    "        not_pet_screening.append(data)\n",
    "print(len(not_pet_screening))\n",
    "for serie in not_pet_screening : \n",
    "    list_json.remove(serie)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nbr de serie pet0/screening :\", len(list_json))"
   ]
  },
  {
   "source": [
    "#### - Reunite CT/PT series with same study uid "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get every study_uid \n",
    "liste = []\n",
    "for data in list_json: \n",
    "    liste.append(data[-2])\n",
    "#print(liste)\n",
    "study_uid = []\n",
    "study_uid.append(liste[0])\n",
    "for uid in liste : \n",
    "    if uid not in study_uid : \n",
    "       study_uid.append(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de study :', len(study_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find serie for each study uid \n",
    "data = []\n",
    "for uid in study_uid : \n",
    "    #print(uid)\n",
    "    sub = []\n",
    "    for serie in list_json : \n",
    "        if uid in serie: \n",
    "            #print(serie)\n",
    "            sub.append(serie)\n",
    "    data.append(sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for serie in data : \n",
    "    #print(serie)\n",
    "    if len(serie) != 1 : \n",
    "        serie[0].append(serie[1][0])\n",
    "        serie[0].append(serie[1][1])\n",
    "        serie[0].append(serie[1][2])\n",
    "\n",
    "    dataset.append(serie[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "source": [
    "#### Clean dataset : if there is no json, double study_uid, if not CT AND PT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no json \n",
    "i = 0\n",
    "no_json_liste = []\n",
    "for data in dataset : \n",
    "    if len(data) != 9 : \n",
    "        i += 1 \n",
    "        no_json_liste.append(data)\n",
    "\n",
    "if i != 0 : \n",
    "    print(\"number of study with no json : {}\".format(i))\n",
    "\n",
    "    for no_json_file in no_json_liste : \n",
    "        no_json_liste.remove(no_json_file)\n",
    "\n",
    "    print(\"dataset cleaned \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double study_uid \n",
    "double = []\n",
    "double.append(dataset[0])\n",
    "for data in dataset : \n",
    "    if data not in double : \n",
    "        double.append(data)\n",
    "\n",
    "if len(double) == len(dataset) : \n",
    "    print('No double study uid, dataset cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Modality \n",
    "index = []\n",
    "for data in dataset : \n",
    "    modal = []\n",
    "    modal.append(data[2])\n",
    "    modal.append(data[-1])\n",
    "    #print(modal)\n",
    "    if modal[0] == modal[1] : \n",
    "        index.append(dataset.index(data))\n",
    "#print(index)\n",
    "#if index is not empty : \n",
    "if len(index) != 0 :\n",
    "    liste_to_remove = []\n",
    "    for ind in index : \n",
    "        liste_to_remove.append(dataset[ind])\n",
    "\n",
    "    for r in liste_to_remove : \n",
    "        dataset.remove(r)\n",
    "\n",
    "print(\"dataset cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de study apr√®s clean :\", len(dataset))"
   ]
  },
  {
   "source": [
    "#### - Sorted  by date studies from 1 patient if necessary "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_patient_id = []\n",
    "for data in dataset : \n",
    "    if data[3] not in liste_patient_id :\n",
    "        liste_patient_id.append(data[3])\n",
    "\n",
    "print(\"Nombre de patients : \", len(liste_patient_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pet_to_sort = []\n",
    "for patient_id in liste_patient_id : \n",
    "    liste = []\n",
    "    for data in dataset : \n",
    "        if patient_id == data[3] : \n",
    "            liste.append(data)\n",
    "\n",
    "    liste_pet_to_sort.append(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(liste_pet_to_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import numpy as np\n",
    "for patient in liste_pet_to_sort : \n",
    "    if len(patient) != 1 : \n",
    "        #liste_date = []\n",
    "        for i in range(len(patient)):\n",
    "            #liste_date.append(datetime.strptime(patient[i][5], \"%Y%m%d\"))\n",
    "            patient[i][5] = datetime.strptime(patient[i][5], \"%Y%m%d\")\n",
    "        #print(patient)\n",
    "        patient.sort(key=lambda patient:patient[5])\n",
    "        for i in range(len(patient)):\n",
    "            patient[i][5] = datetime.strftime(patient[i][5], \"%Y%m%d\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_pet_to_sort[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_date = []\n",
    "for patient in liste_pet_to_sort : \n",
    "    date_liste = []\n",
    "    for i in range(len(patient)):\n",
    "        date_liste.append(patient[i][5])\n",
    "\n",
    "    if len(date_liste) != len(set(date_liste)) : \n",
    "        double_date.append(patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(double_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_file('/media/deeplearning/VERBATIM HD/LNH073B/LNH073B_Validated_DICOM', 'dataset_with_double_examen_v2', double_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pat in double_date :\n",
    "    liste_pet_to_sort.remove(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite path with pet0\n",
    "pet = ['pet0', 'pet2', 'pet4', 'fin']\n",
    "for patient in liste_pet_to_sort : \n",
    "    for i in range(len(patient)) : \n",
    "        patient[i].append(pet[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json_file('/media/deeplearning/VERBATIM HD/LNH073B/LNH073B_Validated_DICOM', 'dataset_validated_per_date_and_type_v2', liste_pet_to_sort)"
   ]
  },
  {
   "source": [
    "#### - Prepare json file to generate nifti in \"nifti_builder_from_json.ipynb\" script"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_results = []\n",
    "for liste in dataset: \n",
    "    #for liste in patient : \n",
    "    subliste = []\n",
    "        #print(liste)\n",
    "    subliste.append(liste[1]) #path_1\n",
    "    subliste.append(liste[2]) #modal 1\n",
    "    subliste.append(liste[-2]) #path_2\n",
    "    subliste.append(liste[-1]) #modal_2\n",
    "    subliste.append(liste[5]) #study_uid\n",
    "    subliste.append(liste[3]) #type\n",
    "    subliste.append(liste[4]) #patient id\n",
    "        #subliste.append(liste[5]) #patient name\n",
    "\n",
    "    study_results.append(subliste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results as json \n",
    "directory = '/media/deeplearning/LACIE SHARE/good'\n",
    "filename = 'ahl_dataset'\n",
    "write_json_file(directory, filename, study_results)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python38264bit4afc185bc98b42c389abdbb3fbeec8dd",
   "display_name": "Python 3.8.2 64-bit",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}