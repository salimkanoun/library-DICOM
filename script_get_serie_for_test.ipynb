{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit9a8409779cd04c3cbd0c5f1e859a644e",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from library_dicom.dicom_processor.tools.folders import *\n",
    "from library_dicom.dicom_processor.tools.series import get_series_object\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = '/home/deeplearning/AHL/AHL_JSON'\n",
    "list_dir_json = os.listdir(json_path)\n",
    "list_json = []\n",
    "\n",
    "remo = [list_dir_json[254]]\n",
    "remo.append(list_dir_json[371])\n",
    "remo.append(list_dir_json[471])\n",
    "for r in remo : \n",
    "    list_dir_json.remove(r)\n",
    "\n",
    "for file_ in list_dir_json : \n",
    "    list_json.append([os.path.join(json_path, file_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_1 = '/home/deeplearning/AHL/AHL_JSON/AHL_JSON_1'\n",
    "list_dir_json_1 = os.listdir(json_path_1)\n",
    "list_json_1 = []\n",
    "for file_ in list_dir_json_1 : \n",
    "    list_json_1.append([os.path.join(json_path_1, file_)])\n",
    "\n",
    "print(len(list_json_1))\n",
    "\n",
    "new_liste = []\n",
    "for data in dataset : \n",
    "    study_uid = data[2]\n",
    "    for json_ in list_json_1 :\n",
    "        #print(json_) \n",
    "        with open(json_[0]) as json_file : \n",
    "            reader = json.load(json_file)\n",
    "\n",
    "            uid_json = reader[\"study\"][\"StudyInstanceUID\"]\n",
    "\n",
    "            if study_uid == uid_json : \n",
    "                new_liste.append(json_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_json = list_json + new_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv \n",
    "csv_path= '/home/deeplearning/AHL/AHL2011_NIFTI.csv'\n",
    "dataset = []\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    dataset = []\n",
    "    for row in reader :\n",
    "        dataset.append(row)\n",
    "        \n",
    "del dataset[0] #enlever premi√®re ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "index = []\n",
    "\n",
    "for liste in list_json : \n",
    "    print(list_json.index(liste))\n",
    "    patient_id = []\n",
    "    study_uid = []\n",
    "    study = []\n",
    "    path = []\n",
    "    manufacturer = []\n",
    "    unit = []\n",
    "    modal = []\n",
    "\n",
    "    with open(liste[0]) as json_file : \n",
    "        reader = json.load(json_file)\n",
    "        for info in reader['study']['StudyInstanceUID'] : \n",
    "                study_uid.append(info)\n",
    "                study_uid_json = \"\".join(study_uid)\n",
    "\n",
    "        for info in reader['patient']['PatientID'] : \n",
    "                patient_id.append(info)\n",
    "                patient_id_json = \"\".join(patient_id)\n",
    "\n",
    "        for info in reader['study']['StudyDescription'] : \n",
    "                study.append(info)\n",
    "                study_json = \"\".join(study)\n",
    "\n",
    "        for info in reader['path'] : \n",
    "                path.append(info)\n",
    "                path_json = \"\".join(path)\n",
    "\n",
    "        for info in reader[\"series\"]['Manufacturer'] : \n",
    "                manufacturer.append(info)\n",
    "                manufacturer_json = \"\".join(manufacturer)\n",
    "\n",
    "\n",
    "        for info in reader[\"series\"][\"Modality\"] : \n",
    "                modal.append(info)\n",
    "                modal_json = \"\".join(modal)\n",
    "\n",
    "        liste.append(path_json)\n",
    "        liste.append(patient_id_json)\n",
    "        liste.append(study_uid_json)\n",
    "        liste.append(study_json)\n",
    "        liste.append(manufacturer_json)\n",
    "        liste.append(modal_json)\n",
    "\n",
    "        if modal_json != 'CT' : \n",
    "\n",
    "                #Units\n",
    "                try : \n",
    "                        for info in reader[\"series\"][\"Units\"] : \n",
    "                                unit.append(info)\n",
    "                                unit_json = \"\".join(unit)\n",
    "\n",
    "                        liste.append(unit_json)\n",
    "                        #philips tags\n",
    "                        if 'philips' in  manufacturer_json.lower(): \n",
    "                                liste.append([reader[\"philips_tags\"]['PhilipsSUVFactor'],reader[\"philips_tags\"][\"PhilipsBqMlFactor\"] ])\n",
    "\n",
    "                        #Radiopharmaceutical Date time\n",
    "                        liste.append(reader[\"radiopharmaceutical\"][\"RadiopharmaceuticalStartDateTime\"])\n",
    "\n",
    "                        #decay correction\n",
    "                        liste.append(reader[\"series\"][\"DecayCorrection\"])\n",
    "\n",
    "                        #series acquisition date \n",
    "                        liste.append(reader[\"series\"][\"AcquisitionDate\"])\n",
    "                        #series acquisition time \n",
    "                        liste.append(reader[\"series\"][\"AcquisitionTime\"])\n",
    "\n",
    "                        #series date\n",
    "                        liste.append(reader[\"series\"][\"SeriesDate\"])\n",
    "                        #serie time \n",
    "                        liste.append(reader[\"series\"]['SeriesTime'])\n",
    "                except Exception as err : \n",
    "                        print(err)\n",
    "                        index.append(list_json.index(liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list PT only \n",
    "PT_series = []\n",
    "for serie in list_json : \n",
    "    if 'PT' in serie : \n",
    "        PT_series.append(serie)"
   ]
  }
 ]
}