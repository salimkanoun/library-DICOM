{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'radiomics'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-849488a2c49f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlibrary_dicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdicom_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyradiomic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/library_dicom/dicom_processor/tools/pyradiomic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mradiomics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatureextractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRadiomicsFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlibrary_dicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdicom_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_mask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'radiomics'"
     ]
    }
   ],
   "source": [
    "from library_dicom.dicom_processor.tools.pyradiomic import *\n",
    "import SimpleITK as sitk \n",
    "import os \n",
    "import numpy as np \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AHL NIFTI \n",
    "csv_path= '/media/oncopole/83c5223d-7a01-4ed0-b268-b877a7da96e2/AHL_NIFTI/AHL2011_NIFTI_V4.csv'\n",
    "with open(csv_path, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    csv_file = []\n",
    "    for row in reader :\n",
    "        csv_file.append(row)\n",
    "        \n",
    "del csv_file[0] #enlever première ligne\n",
    "\n",
    "#AHL NIFTI UNCONSTANT\n",
    "csv_path_2= '/media/oncopole/DD 2To/AHL/NIFTI/AHL2011_NIFTI_unconstant.csv'\n",
    "with open(csv_path_2, 'r') as csv_file :\n",
    "    reader = csv.reader(csv_file, delimiter = ',') #liste pour chaque ligne \n",
    "    csv_file_2 = []\n",
    "    for row in reader :\n",
    "        csv_file_2.append(row)\n",
    "        \n",
    "del csv_file_2[0] #enlever première ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "#### - Keep only pet0 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet0 = []\n",
    "for row in csv_file : \n",
    "    if 'pet0' in row : \n",
    "        pet0.append(row)"
   ]
  },
  {
   "source": [
    "#### - Rewrite abs path "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/media/oncopole/83c5223d-7a01-4ed0-b268-b877a7da96e2'\n",
    "for row in pet0 : \n",
    "    ct = row[-3]\n",
    "    pt = row[-2]\n",
    "    mask = row[-1]\n",
    "    up_ct = os.path.join(base_path, ct)\n",
    "    up_pt = os.path.join(base_path, pt)\n",
    "    up_mask = os.path.join(base_path, mask)\n",
    "    row[-3] = up_ct \n",
    "    row[-2] = up_pt \n",
    "    row[-1] = up_mask"
   ]
  },
  {
   "source": [
    "#### - Prepare dataset "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for data in pet0 : \n",
    "    dataset.append(data)\n",
    "for data in csv_file_2 : \n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find date in json \n",
    "import json \n",
    "liste_json = []\n",
    "list_dir = os.listdir('/media/deeplearning/Elements/AHL_JSON')\n",
    "for file_ in list_dir : \n",
    "    liste_json.append(os.path.join('/media/deeplearning/Elements/AHL_JSON', file_))\n",
    "\n",
    "\n",
    "for data in dataset : \n",
    "    for json_path in liste_json : \n",
    "        with open(json_path) as json_file : \n",
    "            reader = json.load(json_file)\n",
    "\n",
    "            uid = reader['study']['StudyInstanceUID']\n",
    "\n",
    "            if uid == data[2] : \n",
    "\n",
    "                data.append(reader['study']['StudyDate'])\n",
    "\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset : \n",
    "    year = data[-1][0:4]\n",
    "    month = data[-1][4:6]\n",
    "    day = data[-1][6:8]\n",
    "    l = [year, month, day]\n",
    "    date = \"_\".join(l)\n",
    "\n",
    "    data.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if every data has its date\n",
    "cpt = 0\n",
    "for data in dataset : \n",
    "    if len(data) != 9 : \n",
    "        cpt += 1\n",
    "\n",
    "cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_max = []\n",
    "for nifti in dataset: \n",
    "    try : \n",
    "        print(dataset.index(nifti))\n",
    "        liste_center = get_center_of_mass(nifti[-3], thresh = True, pet_path=nifti[-4])\n",
    "        d_max = calcul_distance_max(liste_center)\n",
    "        nifti.append(d_max)\n",
    "    except Exception as err : \n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nifti_directory = '/home/deeplearning/AHL'\n",
    "filename = 'AHL2011_dMax_v3.csv'\n",
    "\n",
    "with open(os.path.join(nifti_directory, filename), 'w') as csv_file : \n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow([\"PATIENT ID\", \"DATE\", \"STUDY_UID\", \"D_MAX\"])\n",
    "    for row in good: \n",
    "        csv_writer.writerow([row[1], row[-2], row[2], row[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}